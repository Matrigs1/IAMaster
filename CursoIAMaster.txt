Large Language Models (LLM's): Modelos de inteligência artificial generativa, com alta escala de processamento de dados. Feitos para interação com seres humanos. Ex: ChatGPT, Lhama, Claude, Gemini.

A OpenIA desenvolveu uma biblioteca dentro do Python que facilita a integração com sistemas, seu nome é 'openai'.

Nela é feita a autenticação do usuário com a API Key, depois, montamos um 'client' com o nosso tipo de retorno de preferência, junto com o 'model' desejado, a 'role' de quem estará fazendo o prompt e, o 'content', que é o conteúdo em si do prompt.

Se a propriedade stream não for passada como True, a resposta será aguardada e mostrada completamente. Caso contrário, é possível mostrar a resposta em pequenas partes, assim como é feito no ChatGPT.

Além da 'role' como user, podemos também passar como sistema, fornecendo um contexto para a Inteligência Artificial. Em sistema, podemos pedir por uma expertise ou, passar dados de uma base, para que as respostas do 'Agent', sejam agora com base nesses dados.

# Atributos customizados
max_tokens = 150  # Limita a quantidade de tokens retornados pela resposta.
temperature 0.2 = # Quanto maior a temperatura, mais randômica será a resposta. Para menores temperaturas, a resposta será mais direta.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
LangChain: Um framework/ecossistema para desenvolvimento de aplicações de inteligência artificial. Facilita e possibilita novos recursos para interação com LLM's e criação de aplicações com elas.

langchain_openai = É uma biblioteca da langchain integrada com a openai. Fornece abstração e facilidades na utilização da IA.

Recursos de cache: 
InMemoryCache() = Esse cache vai ficar em memória enquanto a aplicação estiver rodando. Se a execução parar, ele é perdido. Mas de todo modo, serve para minimizar perguntas e respostas repetidas e otimizar o custo do modelo.
SQLiteCache = Esse tipo de cache irá persistir a resposta em um arquivo .db e, sempre que for chamado, independente se a aplicação for interrompida, buscará o prompt já enviado. Ex:
set_llm_cache(
    SQLiteCache(
        database_path='openai_cache.db'
    )
)

Templates de prompt:
Com o langchain.prompts -> PromptTemplate, é possível criar templates de texto para passar ao modelo, utilizando objetos como interpolação.

ChatPromptTemplate:
É um método para utilizar a interação com a IA e, passar roles de um submódulo para ela. É melhor que utilizar apenas os nomes das roles de forma bruta. Também traz recursos extras.
Roles = SystemMessage, HumanMessage, AIMessage.

Simple Chains:
É uma sintaxe do langchain que permite encadear ações comuns e, que fazem sentido para o sistema. Exemplo: montar um prompt, enviar pro model e dar output da resposta; em vez de fazer isso em etapas separadas, é possível
criar uma 'chain' para essas mesmas etapas.
Como funciona: chain = prompt | model | StrOutputParser()

Router Chain:
Um 'roteador' de chains, que irá direcionar o fluxo de resposta para cada chain específica. Funciona como um 'controler', que vai pegar a pergunta do usuário, classificar ela com a 
ajuda de seu próprio reconhecimento de texto e, de acordo com a pergunta, direcionar ele para a chain classificada. Ex: Pergunta -> Classificação por área ou setor da empresa -> Direcionamento -> Resposta de acordo com o direcionamento.
Cada chain, pode ser envolvido com um RAG, especializado em sua área.

Loaders:
Responsáveis por carregar bases de conhecimento, para serem utilizados pela IA.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Agents:
São dinâmicos, adaptáveis e flexíveis. Capazes de executarem tarefas e altamente treinados no ambiente. São disponibilizadas ferramentas para a interação com o agente.

Tools:
São as ferramentas (libs) que disponibilizamos para os agentes. Existem ferramentas de busca na internet, interação com banco de dados, executar shell, executar códigos Python etc.


